{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MiaMiya/02807-Computational-Tools-for-Data-Science/blob/main/Week7/exercises_week_7_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlMcbNUbMqnF"
   },
   "source": [
    "# 02807 - Week 7 Exercises:  Getting started with Spark, Solutions\n",
    "**To learn the most, please find your own solutions before conferring with the ones provided below**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXQzA01OS_yQ"
   },
   "source": [
    "# Setup\n",
    "\n",
    "* See also this week's slides for context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:00.219855Z",
     "start_time": "2021-10-11T19:20:59.476023Z"
    },
    "id": "07uWWQAHu84c",
    "outputId": "82eab93d-8527-4780-9f57-4ec0c32015d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\miaha\\appdata\\roaming\\python\\python37\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\miaha\\appdata\\roaming\\python\\python37\\site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:00.223652Z",
     "start_time": "2021-10-11T19:21:00.221268Z"
    },
    "id": "dhzk3GE6S9RC"
   },
   "outputs": [],
   "source": [
    "# Instructions on p. 20 Learning Spark, 2nd ed.\n",
    "# Here's a quick-guide, googling may also be required\n",
    "# 1) Install pyspark via conda/pip\n",
    "#          pyspark requires the JAVA_HOME environment variable is set.\n",
    "# 2) Install JRE/JDK, figure out the install location\n",
    "#          You will need to install Java 8 or above\n",
    "# 3) Update the JAVA_HOME environment variable set programmatically below \n",
    "#    with your installation specifics\n",
    "\n",
    "# Some maybe helpful pointers on JRE/JDK:\n",
    "# MacOS: Consider using https://github.com/AdoptOpenJDK/homebrew-openjdk\n",
    "# Debian (colab): !apt install openjdk-8-jdk-headless -qq\n",
    "# Windows: \n",
    "#    If you didn't change the path during installation, it'll be \n",
    "#    something like C:\\Program Files\\Java\\jdk1.8.0_65\n",
    "#    You can also type where java at the command prompt.\n",
    "\n",
    "# JAVA_HOME environment variable is set programatically below\n",
    "# but you must point it to your local install\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Programmer\\Java\\jdk-14.0.2\"\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:00.533785Z",
     "start_time": "2021-10-11T19:21:00.224806Z"
    },
    "id": "xgQaRx6rSaf9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUD5XpD_SagA"
   },
   "source": [
    "Let's initialise a **Spark Session**. \n",
    "* A SparkSession object is the entry point to the Spark functionality. \n",
    "* When you create the SparkSession object, it initiates a **Spark Application** which all the code for that Session will run on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:04.257817Z",
     "start_time": "2021-10-11T19:21:00.534459Z"
    },
    "id": "7ft3VivrSagB"
   },
   "outputs": [],
   "source": [
    "# create the Spark session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:04.981186Z",
     "start_time": "2021-10-11T19:21:04.258838Z"
    },
    "id": "sw-bxDJ_u84g",
    "outputId": "6c7a3a0b-141d-4e31-cdf9-43c66396dc66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.16.142.168:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d2f9369f08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ectQxRreAvJ"
   },
   "source": [
    "# Exercise 1: The Titanic Dataset\n",
    "\n",
    "In this exercise you should use Spark to count the number of Titanic passengers in different age brackets. More specifically, you need to count the number of people age 0 to 9, 10 to 19, and so on.\n",
    "\n",
    "The data is available [here](https://courses.compute.dtu.dk/02807/2021/lectures/week7/titanic_full.csv) and should be loaded into a dataframe in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:10.530761Z",
     "start_time": "2021-10-11T19:21:04.981878Z"
    },
    "id": "my6Awbl-e4AO"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "df = spark.read.format('jdbc').option('header', True).option('inferSchema', True).csv('titanic_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSZvg7eOe7ok"
   },
   "source": [
    "## Cleaning the data\n",
    "\n",
    "Remove the rows that do not have an age \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:10.559531Z",
     "start_time": "2021-10-11T19:21:10.531562Z"
    },
    "id": "OJrRTjQLfTsq"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "df = df.filter(F.col('Age').isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jzO0ggSfAFs"
   },
   "source": [
    "## Adding age brackets \n",
    "\n",
    "Create a new column with a value that identifies the bracket that passengers are in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:11.995971Z",
     "start_time": "2021-10-11T19:21:10.560358Z"
    },
    "id": "S2bOTGcpfIES",
    "outputId": "88e992e5-faa7-4e0c-ef4d-3a2c542770f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-------------+\n",
      "| Age|AgeBracketUDF|AgeBracketDiv|\n",
      "+----+-------------+-------------+\n",
      "|22.0|        20-29|           20|\n",
      "|38.0|        30-39|           30|\n",
      "|26.0|        20-29|           20|\n",
      "|35.0|        30-39|           30|\n",
      "|35.0|        30-39|           30|\n",
      "|54.0|        50-59|           50|\n",
      "| 2.0|          0-9|            0|\n",
      "|27.0|        20-29|           20|\n",
      "|14.0|        10-19|           10|\n",
      "| 4.0|          0-9|            0|\n",
      "|58.0|        50-59|           50|\n",
      "|20.0|        20-29|           20|\n",
      "|39.0|        30-39|           30|\n",
      "|14.0|        10-19|           10|\n",
      "|55.0|        50-59|           50|\n",
      "| 2.0|          0-9|            0|\n",
      "|31.0|        30-39|           30|\n",
      "|35.0|        30-39|           30|\n",
      "|34.0|        30-39|           30|\n",
      "|15.0|        10-19|           10|\n",
      "+----+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "def age_bracket(age):\n",
    "    for bracket in range(10, 150, 10):\n",
    "        if age < bracket:\n",
    "            return f\"{bracket-10}-{bracket-1}\"\n",
    "        \n",
    "age_bracket_udf = F.udf(age_bracket)\n",
    "\n",
    "df = df.withColumn('AgeBracketUDF', age_bracket_udf(F.col('Age'))) \\\n",
    "        .withColumn('AgeBracketDiv', (F.col('Age') / 10).cast('integer')*10)\n",
    "\n",
    "df.select('Age', 'AgeBracketUDF', 'AgeBracketDiv').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCLsqtqVfKwb"
   },
   "source": [
    "## Age bracket counts\n",
    "\n",
    "Create a Spark dataframe with the sum of passengers in each bracket, and sort it by Age Bracket (youngest to oldest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:17.232753Z",
     "start_time": "2021-10-11T19:21:11.996630Z"
    },
    "id": "wm9fldBlfVmK",
    "outputId": "58afd90b-8415-48db-8b72-709d85ea28f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AgeBracketUDF='0-9', AgeBracketDiv=0, count(AgeBracketUDF)=62, count(AgeBracketDiv)=62),\n",
       " Row(AgeBracketUDF='10-19', AgeBracketDiv=10, count(AgeBracketUDF)=102, count(AgeBracketDiv)=102),\n",
       " Row(AgeBracketUDF='20-29', AgeBracketDiv=20, count(AgeBracketUDF)=220, count(AgeBracketDiv)=220),\n",
       " Row(AgeBracketUDF='30-39', AgeBracketDiv=30, count(AgeBracketUDF)=167, count(AgeBracketDiv)=167),\n",
       " Row(AgeBracketUDF='40-49', AgeBracketDiv=40, count(AgeBracketUDF)=89, count(AgeBracketDiv)=89),\n",
       " Row(AgeBracketUDF='50-59', AgeBracketDiv=50, count(AgeBracketUDF)=48, count(AgeBracketDiv)=48),\n",
       " Row(AgeBracketUDF='60-69', AgeBracketDiv=60, count(AgeBracketUDF)=19, count(AgeBracketDiv)=19),\n",
       " Row(AgeBracketUDF='70-79', AgeBracketDiv=70, count(AgeBracketUDF)=6, count(AgeBracketDiv)=6),\n",
       " Row(AgeBracketUDF='80-89', AgeBracketDiv=80, count(AgeBracketUDF)=1, count(AgeBracketDiv)=1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "df.groupBy('AgeBracketUDF', 'AgeBracketDiv') \\\n",
    "    .agg(F.count('AgeBracketUDF'), F.count('AgeBracketDiv')) \\\n",
    "    .sort('AgeBracketUDF', 'AgeBracketDiv') \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEBjObzYu84j"
   },
   "source": [
    "## Spark plans and jobs\n",
    "\n",
    "1) Display the plans spark creates to achieve your query in the previous exercise. Identify how many shuffles/exchanges are to take place.\n",
    "\n",
    "2) How many jobs are spawned when your query is executed? (Inspect via the Spark UI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LquSr-uMu84k"
   },
   "source": [
    "*Your answers here*\n",
    "\n",
    "1) Two Exchanges are to take place, firstly hashpartioned, secondly rangepartioned.\n",
    "\n",
    "2) Two jobs were spawned. The second job skips a stage and reads from the shuffle created (and cached) by the first job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:17.389778Z",
     "start_time": "2021-10-11T19:21:17.233531Z"
    },
    "id": "Tx1s3LSYu84k",
    "outputId": "a5f6c18e-9234-4c32-d771-e1232eb04310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) Sort [AgeBracketUDF#41 ASC NULLS FIRST, AgeBracketDiv#55 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(AgeBracketUDF#41 ASC NULLS FIRST, AgeBracketDiv#55 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#148]\n",
      "   +- *(3) HashAggregate(keys=[AgeBracketUDF#41, AgeBracketDiv#55], functions=[count(AgeBracketUDF#41), count(AgeBracketDiv#55)])\n",
      "      +- Exchange hashpartitioning(AgeBracketUDF#41, AgeBracketDiv#55, 200), ENSURE_REQUIREMENTS, [id=#144]\n",
      "         +- *(2) HashAggregate(keys=[AgeBracketUDF#41, AgeBracketDiv#55], functions=[partial_count(AgeBracketUDF#41), partial_count(AgeBracketDiv#55)])\n",
      "            +- *(2) Project [pythonUDF0#138 AS AgeBracketUDF#41, (cast((Age#21 / 10.0) as int) * 10) AS AgeBracketDiv#55]\n",
      "               +- BatchEvalPython [age_bracket(Age#21)], [pythonUDF0#138]\n",
      "                  +- *(1) Filter isnotnull(Age#21)\n",
      "                     +- FileScan csv [Age#21] Batched: false, DataFilters: [isnotnull(Age#21)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/miaha/OneDrive/Dokumenter/DTU/Msc/1.Semester/02807-Computational..., PartitionFilters: [], PushedFilters: [IsNotNull(Age)], ReadSchema: struct<Age:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "df.groupBy('AgeBracketUDF', 'AgeBracketDiv') \\\n",
    "    .agg(F.count('AgeBracketUDF'), F.count('AgeBracketDiv')) \\\n",
    "    .sort('AgeBracketUDF', 'AgeBracketDiv') \\\n",
    "    .explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvB1CeqSfYXP"
   },
   "source": [
    "# Exercise 2: Actions and transformations\n",
    "\n",
    "For each of the following Spark operations, decide if they are transformations or actions. If they are transformations, determine if they are wide or narrow.\n",
    "\n",
    "* ``select()``\n",
    "* `groupBy()`\n",
    "* `filter()`\n",
    "* `where()`\n",
    "* `count()`\n",
    "* `show()`\n",
    "* `agg()`\n",
    "* `write()`\n",
    "* `sort()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MQ2mtJLfu5_"
   },
   "source": [
    "*Your answers here*\n",
    "\n",
    "* `select()` is a narrow transformation\n",
    "* `groupBy()` is a wide transformation as we must gather groups from different partitions\n",
    "* `filter()` is a narrow transformation - we can filter each individual partition\n",
    "* `where()` is a narrow transformation, an alias for filter\n",
    "* `count()` is an action, or a wide transformation when done on a groupeddataset\n",
    "* `show()` is an action\n",
    "* `agg()` is a wide transformation\n",
    "* `write()` is an action \n",
    "* `sort` is a wide transformation as we must sort across partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wztxj5t_6m-h"
   },
   "source": [
    "# Exercise 3: Exploratory data analysis for the Chicago crime dataset\n",
    "The Chicago Crime dataset contains a summary of the reported crimes occurred in the City of Chicago from 2001 to 2017. \n",
    "\n",
    "We'll work on a sample of it available [here](https://courses.compute.dtu.dk/02807/2021/lectures/week7/reported-crimes.csv).\n",
    "\n",
    "You may optionally work on the entire dataset which is available [here](https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD).\n",
    "\n",
    "Now load the data you've downloaded locally into a spark dataframe, and proceed to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:18.250836Z",
     "start_time": "2021-10-11T19:21:17.390517Z"
    },
    "id": "EfnqE8Jx_Eve",
    "outputId": "dd73df12-4788-4336-e35d-294f23982cb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>DATE</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>PRIMARY_TYPE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>LOCATION_DESCRIPTION</th>\n",
       "      <th>ARREST</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>...</th>\n",
       "      <th>WARD</th>\n",
       "      <th>COMMUNITY_AREA_NUMBER</th>\n",
       "      <th>FBICODE</th>\n",
       "      <th>X_COORDINATE</th>\n",
       "      <th>Y_COORDINATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>UPDATEDON</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3512276</td>\n",
       "      <td>HK587712</td>\n",
       "      <td>08/28/2004 05:50:56 PM</td>\n",
       "      <td>047XX S KEDZIE AVE</td>\n",
       "      <td>890</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>FROM BUILDING</td>\n",
       "      <td>SMALL RETAIL STORE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>1155838</td>\n",
       "      <td>1873050</td>\n",
       "      <td>2004</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.8074405</td>\n",
       "      <td>-87.70395585</td>\n",
       "      <td>(41.8074405, -87.703955849)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3406613</td>\n",
       "      <td>HK456306</td>\n",
       "      <td>06/26/2004 12:40:00 PM</td>\n",
       "      <td>009XX N CENTRAL PARK AVE</td>\n",
       "      <td>820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1152206</td>\n",
       "      <td>1906127</td>\n",
       "      <td>2004</td>\n",
       "      <td>02/28/2018 03:56:25 PM</td>\n",
       "      <td>41.89827996</td>\n",
       "      <td>-87.71640551</td>\n",
       "      <td>(41.898279962, -87.716405505)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002131</td>\n",
       "      <td>HT233595</td>\n",
       "      <td>04/04/2011 05:45:00 AM</td>\n",
       "      <td>043XX S WABASH AVE</td>\n",
       "      <td>820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>NURSING HOME/RETIREMENT HOME</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>1177436</td>\n",
       "      <td>1876313</td>\n",
       "      <td>2011</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.81593313</td>\n",
       "      <td>-87.62464213</td>\n",
       "      <td>(41.815933131, -87.624642127)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID CASE_NUMBER                    DATE                     BLOCK IUCR  \\\n",
       "0  3512276    HK587712  08/28/2004 05:50:56 PM        047XX S KEDZIE AVE  890   \n",
       "1  3406613    HK456306  06/26/2004 12:40:00 PM  009XX N CENTRAL PARK AVE  820   \n",
       "2  8002131    HT233595  04/04/2011 05:45:00 AM        043XX S WABASH AVE  820   \n",
       "\n",
       "  PRIMARY_TYPE     DESCRIPTION          LOCATION_DESCRIPTION ARREST DOMESTIC  \\\n",
       "0        THEFT   FROM BUILDING            SMALL RETAIL STORE  FALSE    FALSE   \n",
       "1        THEFT  $500 AND UNDER                         OTHER  FALSE    FALSE   \n",
       "2        THEFT  $500 AND UNDER  NURSING HOME/RETIREMENT HOME  FALSE    FALSE   \n",
       "\n",
       "   ... WARD COMMUNITY_AREA_NUMBER FBICODE X_COORDINATE Y_COORDINATE  YEAR  \\\n",
       "0  ...   14                    58       6      1155838      1873050  2004   \n",
       "1  ...   27                    23       6      1152206      1906127  2004   \n",
       "2  ...    3                    38       6      1177436      1876313  2011   \n",
       "\n",
       "                UPDATEDON     LATITUDE     LONGITUDE  \\\n",
       "0  02/10/2018 03:50:01 PM   41.8074405  -87.70395585   \n",
       "1  02/28/2018 03:56:25 PM  41.89827996  -87.71640551   \n",
       "2  02/10/2018 03:50:01 PM  41.81593313  -87.62464213   \n",
       "\n",
       "                        LOCATION  \n",
       "0    (41.8074405, -87.703955849)  \n",
       "1  (41.898279962, -87.716405505)  \n",
       "2  (41.815933131, -87.624642127)  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "rc = spark.read.csv('reported-crimes.csv', header=True)\n",
    "rc.toPandas().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DknyPxfkFFVz"
   },
   "source": [
    "## What percentage of reported crimes resulted in an arrest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:18.927491Z",
     "start_time": "2021-10-11T19:21:18.251511Z"
    },
    "id": "d9S4hZanFPCf",
    "outputId": "e116d72c-bc2f-4770-9d33-b81fdccf3b2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.58161350844278, 'percent out of', 533, 'reports')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "(rc.filter(F.col('ARREST') == 'TRUE').count() / rc.count()) * 100, 'percent out of', rc.count(), 'reports'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uToZfa01Fqi9"
   },
   "source": [
    "## What are the top 3 locations for reported crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:20.294960Z",
     "start_time": "2021-10-11T19:21:18.928389Z"
    },
    "id": "B3bxfL6wFvjJ",
    "outputId": "9bcfa872-24d0-4373-a979-55574c96334f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION_DESCRIPTION</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STREET</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION_DESCRIPTION  count\n",
       "0               STREET    136\n",
       "1            RESIDENCE     84\n",
       "2             SIDEWALK     64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "rc.groupBy('LOCATION_DESCRIPTION').count() \\\n",
    "    .sort(F.desc('count')) \\\n",
    "    .limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYiThcrJu84n"
   },
   "source": [
    "## What are the top 3 locations for reported thefts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:21.481933Z",
     "start_time": "2021-10-11T19:21:20.295663Z"
    },
    "id": "UzDl7vv2u84n",
    "outputId": "181ab573-a8ae-4252-f710-975aaf2177f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION_DESCRIPTION</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STREET</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GROCERY FOOD STORE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPARTMENT STORE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION_DESCRIPTION  count\n",
       "0               STREET     31\n",
       "1   GROCERY FOOD STORE      7\n",
       "2     DEPARTMENT STORE      7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "rc.filter(F.col('PRIMARY_TYPE') == 'THEFT') \\\n",
    "    .groupBy('LOCATION_DESCRIPTION').count() \\\n",
    "    .sort(F.desc('count')) \\\n",
    "    .limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI6uPOV7GCAH"
   },
   "source": [
    "## What is the most common primary type of crime in district 22?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:22.594342Z",
     "start_time": "2021-10-11T19:21:21.482968Z"
    },
    "id": "ojh8eHFUGNG9",
    "outputId": "2330f923-ce6d-4778-ecc4-ddc5c763b8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|PRIMARY_TYPE|count|\n",
      "+------------+-----+\n",
      "|       THEFT|    6|\n",
      "|    BURGLARY|    2|\n",
      "|     BATTERY|    1|\n",
      "+------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "rc.filter(F.col('DISTRICT') == '22') \\\n",
    "    .groupBy(F.col('PRIMARY_TYPE')).count() \\\n",
    "    .sort(F.desc('count')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDlBTI1qu84o"
   },
   "source": [
    "## What are the suffixes where crime is taking place?\n",
    "\n",
    "Inspect the `BLOCK` column to observe common suffixes are `AVE, BLVD, ST, DR, PL, RD` (there's a few more even). Create a dataframe that contains the frequency of each block suffix, e.g. showing there are 258 `AVE` suffixes and 191 `ST` suffixes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:23.567242Z",
     "start_time": "2021-10-11T19:21:22.595182Z"
    },
    "id": "CONfH8Tfu84o",
    "outputId": "92407b07-e44c-4307-fb8e-97a9533e189c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>suffix</th>\n",
       "      <th>PL</th>\n",
       "      <th>DR</th>\n",
       "      <th>AV</th>\n",
       "      <th>BROADWAY</th>\n",
       "      <th>E</th>\n",
       "      <th>PKWY</th>\n",
       "      <th>BL</th>\n",
       "      <th>CT</th>\n",
       "      <th>D</th>\n",
       "      <th>RD</th>\n",
       "      <th>AVE</th>\n",
       "      <th>Ave</th>\n",
       "      <th>TER</th>\n",
       "      <th>BLVD</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "suffix  PL  DR  AV  BROADWAY  E  PKWY  BL  CT  D  RD  AVE  Ave  TER  BLVD   ST\n",
       "count    9  11  25         2  1     2   2   1  1  13  258    1    1    15  191"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "rc.select(\n",
    "    F.reverse(F.split('BLOCK', ' '))[0].alias('suffix')\n",
    ").groupby('suffix').count().toPandas().set_index('suffix').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T19:21:24.285509Z",
     "start_time": "2021-10-11T19:21:23.568048Z"
    },
    "id": "QC74KHMUu84o",
    "outputId": "fbd376ba-3968-485a-bb77-489256051399"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum(AVE)</th>\n",
       "      <th>sum(BLVD)</th>\n",
       "      <th>sum(ST)</th>\n",
       "      <th>sum(DR)</th>\n",
       "      <th>sum(PL)</th>\n",
       "      <th>sum(RD)</th>\n",
       "      <th>sum(PKWY)</th>\n",
       "      <th>sum(CT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284</td>\n",
       "      <td>15</td>\n",
       "      <td>191</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum(AVE)  sum(BLVD)  sum(ST)  sum(DR)  sum(PL)  sum(RD)  sum(PKWY)  sum(CT)\n",
       "0       284         15      191       11        9       13          2        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This more verbose option gives more granular control\n",
    "\n",
    "rc.select(F.lower('BLOCK').alias('block')) \\\n",
    "    .select(\n",
    "    F.col('block').endswith('ave').alias('AVE').cast('integer'),\n",
    "    F.col('block').endswith('av').alias('AV').cast('integer'),\n",
    "    F.col('block').endswith('blvd').alias('BLVD').cast('integer'),\n",
    "    F.col('block').endswith('st').alias('ST').cast('integer'),\n",
    "    F.col('block').endswith('dr').alias('DR').cast('integer'),\n",
    "    F.col('block').endswith('pl').alias('PL').cast('integer'),\n",
    "    F.col('block').endswith('rd').alias('RD').cast('integer'),\n",
    "    F.col('block').endswith('pkwy').alias('PKWY').cast('integer'),\n",
    "    F.col('block').endswith('ct').alias('CT').cast('integer')\n",
    ").agg(\n",
    "    (F.sum('AVE') + F.sum('AV')).alias('sum(AVE)'), \n",
    "    F.sum('BLVD'), F.sum('ST'), \n",
    "    F.sum('DR'), F.sum('PL'), \n",
    "    F.sum('RD'), F.sum('PKWY'), \n",
    "    F.sum('CT')\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "exercises_week_7_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
